{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92f6a89-2979-4156-9f90-08ed8455a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned Data Sample:\n",
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "\n",
      "✅ After Removing Outliers:\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    149.000000   149.000000    149.000000   149.000000\n",
      "mean       5.844295     3.048322      3.773154     1.204698\n",
      "std        0.830775     0.423085      1.761435     0.761962\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.400000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.200000      6.900000     2.500000\n",
      "\n",
      "✅ Transformed Features:\n",
      "   sepal.length  sepal.width  petal.length  petal.width\n",
      "0     -0.898927     1.071184     -1.351829    -1.323014\n",
      "1     -1.140478    -0.114599     -1.351829    -1.323014\n",
      "2     -1.382029     0.359714     -1.408792    -1.323014\n",
      "3     -1.502804     0.122557     -1.294865    -1.323014\n",
      "4     -1.019702     1.308340     -1.351829    -1.323014\n",
      "\n",
      "✅ Accuracy Comparison:\n",
      "Logistic Regression Accuracy: 90.00%\n",
      "Naive Bayes Accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "\n",
    "# --- e. Data Cleaning ---\n",
    "df = pd.read_csv(\"/Users/akshay/Desktop/dsbda_practical/newdata/iris.csv\")\n",
    "\n",
    "# Remove '?' and NA values\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert to numeric where applicable\n",
    "for col in df.columns[:-1]:  # skip 'variety'\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "# Remove rows with any negative values\n",
    "df = df[(df.select_dtypes(include=[np.number]) >= 0).all(axis=1)]\n",
    "\n",
    "print(\"✅ Cleaned Data Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# --- f. Error Correcting (Outlier Detection and Removal) ---\n",
    "# Use Z-score method to detect outliers\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "z_scores = np.abs(stats.zscore(numeric_df))\n",
    "df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "print(\"\\n✅ After Removing Outliers:\")\n",
    "print(df.describe())\n",
    "\n",
    "# --- g. Data Transformation ---\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "df['variety_encoded'] = le.fit_transform(df['variety'])\n",
    "\n",
    "# Normalize features\n",
    "X = df.drop(['variety', 'variety_encoded'], axis=1)\n",
    "y = df['variety_encoded']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\n✅ Transformed Features:\")\n",
    "print(pd.DataFrame(X_scaled, columns=X.columns).head())\n",
    "\n",
    "# --- h. Build Model using Regression and Naïve Bayes ---\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=200)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_preds)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_preds = nb_model.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "# --- Results ---\n",
    "print(\"\\n✅ Accuracy Comparison:\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_acc * 100:.2f}%\")\n",
    "print(f\"Naive Bayes Accuracy: {nb_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86220f86-310a-4f0d-a8c7-7ccbc7d8ba9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
