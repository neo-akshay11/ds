{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f086d1de-e7dc-4b14-bdc1-14a969006304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: Setosa\n",
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "\n",
      "Merged DataFrame (Setosa + Versicolor):\n",
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "\n",
      "Data Sorted by Petal Length:\n",
      "    sepal.length  sepal.width  petal.length  petal.width variety\n",
      "22           4.6          3.6           1.0          0.2  Setosa\n",
      "13           4.3          3.0           1.1          0.1  Setosa\n",
      "14           5.8          4.0           1.2          0.2  Setosa\n",
      "35           5.0          3.2           1.2          0.2  Setosa\n",
      "36           5.5          3.5           1.3          0.2  Setosa\n",
      "\n",
      "Transposed Data (first 5 rows):\n",
      "                   0       1       2       3       4\n",
      "sepal.length     5.1     4.9     4.7     4.6     5.0\n",
      "sepal.width      3.5     3.0     3.2     3.1     3.6\n",
      "petal.length     1.4     1.4     1.3     1.5     1.4\n",
      "petal.width      0.2     0.2     0.2     0.2     0.2\n",
      "variety       Setosa  Setosa  Setosa  Setosa  Setosa\n",
      "\n",
      "Melted Data (Long Format):\n",
      "   index variety       feature  value\n",
      "0      0  Setosa  sepal.length    5.1\n",
      "1      1  Setosa  sepal.length    4.9\n",
      "2      2  Setosa  sepal.length    4.7\n",
      "3      3  Setosa  sepal.length    4.6\n",
      "4      4  Setosa  sepal.length    5.0\n",
      "\n",
      "Casted Data (Wide Format):\n",
      "   index  petal.length  petal.width  sepal.length  sepal.width variety\n",
      "0      0           1.4          0.2           5.1          3.5  Setosa\n",
      "1      1           1.4          0.2           4.9          3.0  Setosa\n",
      "2      2           1.3          0.2           4.7          3.2  Setosa\n",
      "3      3           1.5          0.2           4.6          3.1  Setosa\n",
      "4      4           1.4          0.2           5.0          3.6  Setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/akshay/Desktop/dsbda_practical/newdata/iris.csv\")\n",
    "\n",
    "# --- g. Create data subsets for different species ---\n",
    "setosa = df[df['variety'] == 'Setosa']\n",
    "versicolor = df[df['variety'] == 'Versicolor']\n",
    "virginica = df[df['variety'] == 'Virginica']\n",
    "\n",
    "print(\"Subset: Setosa\")\n",
    "print(setosa.head())\n",
    "\n",
    "# --- h. Merge two subsets (Setosa + Versicolor) ---\n",
    "merged_df = pd.concat([setosa, versicolor])\n",
    "print(\"\\nMerged DataFrame (Setosa + Versicolor):\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# --- i. Sort Data by Petal Length ---\n",
    "sorted_df = df.sort_values(by='petal.length')\n",
    "print(\"\\nData Sorted by Petal Length:\")\n",
    "print(sorted_df.head())\n",
    "\n",
    "# --- j. Transposing Data (first 5 rows) ---\n",
    "transposed_df = df.head().transpose()\n",
    "print(\"\\nTransposed Data (first 5 rows):\")\n",
    "print(transposed_df)\n",
    "\n",
    "# --- k. Melting Data to Long Format ---\n",
    "df = df.reset_index()  # Assign a unique index column\n",
    "melted_df = pd.melt(df, \n",
    "                    id_vars=['index', 'variety'], \n",
    "                    value_vars=['sepal.length', 'sepal.width', 'petal.length', 'petal.width'],\n",
    "                    var_name='feature', \n",
    "                    value_name='value')\n",
    "print(\"\\nMelted Data (Long Format):\")\n",
    "print(melted_df.head())\n",
    "\n",
    "# --- l. Casting Data to Wide Format (Fixed) ---\n",
    "wide_df = melted_df.pivot_table(index='index', \n",
    "                                 columns='feature', \n",
    "                                 values='value')\n",
    "\n",
    "# Add variety column back using a merge on index\n",
    "wide_df = wide_df.merge(df[['index', 'variety']], on='index')\n",
    "print(\"\\nCasted Data (Wide Format):\")\n",
    "print(wide_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9c3fab-467c-4bfe-80d5-aefb06a7c54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "df.pivot_table(\n",
       "    values=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    index=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    aggfunc: \u001b[33m'AggFuncType'\u001b[39m = \u001b[33m'mean'\u001b[39m,\n",
       "    fill_value=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    margins: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    dropna: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "    margins_name: \u001b[33m'Level'\u001b[39m = \u001b[33m'All'\u001b[39m,\n",
       "    observed: \u001b[33m'bool | lib.NoDefault'\u001b[39m = <no_default>,\n",
       "    sort: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       ") -> \u001b[33m'DataFrame'\u001b[39m\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Create a spreadsheet-style pivot table as a DataFrame.\n",
       "\n",
       "The levels in the pivot table will be stored in MultiIndex objects\n",
       "(hierarchical indexes) on the index and columns of the result DataFrame.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "values : list-like or scalar, optional\n",
       "    Column or columns to aggregate.\n",
       "index : column, Grouper, array, or list of the previous\n",
       "    Keys to group by on the pivot table index. If a list is passed,\n",
       "    it can contain any of the other types (except list). If an array is\n",
       "    passed, it must be the same length as the data and will be used in\n",
       "    the same manner as column values.\n",
       "columns : column, Grouper, array, or list of the previous\n",
       "    Keys to group by on the pivot table column. If a list is passed,\n",
       "    it can contain any of the other types (except list). If an array is\n",
       "    passed, it must be the same length as the data and will be used in\n",
       "    the same manner as column values.\n",
       "aggfunc : function, list of functions, dict, default \"mean\"\n",
       "    If a list of functions is passed, the resulting pivot table will have\n",
       "    hierarchical columns whose top level are the function names\n",
       "    (inferred from the function objects themselves).\n",
       "    If a dict is passed, the key is column to aggregate and the value is\n",
       "    function or list of functions. If ``margin=True``, aggfunc will be\n",
       "    used to calculate the partial aggregates.\n",
       "fill_value : scalar, default None\n",
       "    Value to replace missing values with (in the resulting pivot table,\n",
       "    after aggregation).\n",
       "margins : bool, default False\n",
       "    If ``margins=True``, special ``All`` columns and rows\n",
       "    will be added with partial group aggregates across the categories\n",
       "    on the rows and columns.\n",
       "dropna : bool, default True\n",
       "    Do not include columns whose entries are all NaN. If True,\n",
       "    rows with a NaN value in any column will be omitted before\n",
       "    computing margins.\n",
       "margins_name : str, default 'All'\n",
       "    Name of the row / column that will contain the totals\n",
       "    when margins is True.\n",
       "observed : bool, default False\n",
       "    This only applies if any of the groupers are Categoricals.\n",
       "    If True: only show observed values for categorical groupers.\n",
       "    If False: show all values for categorical groupers.\n",
       "\n",
       "    .. deprecated:: 2.2.0\n",
       "\n",
       "        The default value of ``False`` is deprecated and will change to\n",
       "        ``True`` in a future version of pandas.\n",
       "\n",
       "sort : bool, default True\n",
       "    Specifies if the result should be sorted.\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    An Excel style pivot table.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.pivot : Pivot without aggregation that can handle\n",
       "    non-numeric data.\n",
       "DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
       "    optionally leaving identifiers set.\n",
       "wide_to_long : Wide panel to long format. Less flexible but more\n",
       "    user-friendly than melt.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
       "...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
       "...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
       "...                          \"one\", \"one\", \"two\", \"two\"],\n",
       "...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
       "...                          \"small\", \"large\", \"small\", \"small\",\n",
       "...                          \"large\"],\n",
       "...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
       "...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
       ">>> df\n",
       "     A    B      C  D  E\n",
       "0  foo  one  small  1  2\n",
       "1  foo  one  large  2  4\n",
       "2  foo  one  large  2  5\n",
       "3  foo  two  small  3  5\n",
       "4  foo  two  small  3  6\n",
       "5  bar  one  large  4  6\n",
       "6  bar  one  small  5  8\n",
       "7  bar  two  small  6  9\n",
       "8  bar  two  large  7  9\n",
       "\n",
       "This first example aggregates values by taking the sum.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                        columns=['C'], aggfunc=\"sum\")\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one    4.0    5.0\n",
       "    two    7.0    6.0\n",
       "foo one    4.0    1.0\n",
       "    two    NaN    6.0\n",
       "\n",
       "We can also fill missing values using the `fill_value` parameter.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                        columns=['C'], aggfunc=\"sum\", fill_value=0)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one      4      5\n",
       "    two      7      6\n",
       "foo one      4      1\n",
       "    two      0      6\n",
       "\n",
       "The next example aggregates by taking the mean across multiple columns.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                        aggfunc={'D': \"mean\", 'E': \"mean\"})\n",
       ">>> table\n",
       "                D         E\n",
       "A   C\n",
       "bar large  5.500000  7.500000\n",
       "    small  5.500000  8.500000\n",
       "foo large  2.000000  4.500000\n",
       "    small  2.333333  4.333333\n",
       "\n",
       "We can also calculate multiple types of aggregations for any given\n",
       "value column.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                        aggfunc={'D': \"mean\",\n",
       "...                                 'E': [\"min\", \"max\", \"mean\"]})\n",
       ">>> table\n",
       "                  D   E\n",
       "               mean max      mean  min\n",
       "A   C\n",
       "bar large  5.500000   9  7.500000    6\n",
       "    small  5.500000   9  8.500000    8\n",
       "foo large  2.000000   5  4.500000    4\n",
       "    small  2.333333   6  4.333333    2\n",
       "\u001b[31mFile:\u001b[39m      /opt/homebrew/Cellar/jupyterlab/4.4.1_1/libexec/lib/python3.13/site-packages/pandas/core/frame.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.pivot_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5472de4-a4c0-4d86-af94-95442ad8406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
